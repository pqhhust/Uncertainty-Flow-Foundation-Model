_target_: src.models.distill_flow_module.DistillFlowModule

model_name: "Qwen/Qwen2.5-0.5B"
teacher_ckpt_path: null  # Path to fine-tuned teacher checkpoint
num_labels: 2
from_layer: 6
to_layer: 18
dit_depth: 2
mlp_ratio: 4.0
dropout: 0.1
teacher_dropout: 0.1  # Dropout on teacher hidden states (stochastic velocity targets)
scale_div: 1000.0  # Divide hidden states by this factor before flow matching (stabilizes training)
use_interpolation: false  # CFM interpolation between layer boundaries (for loss_type=velocity)
loss_type: "velocity"  # "velocity" = single-step Flow Recompilation | "meanflow" = multi-scale MeanFlow
data_proportion: 0.5  # MeanFlow: fraction of batch using single-step intervals (rest uses multi-step)
num_inference_steps: null  # Override flow integration steps at inference (null = use num_steps = to_layer - from_layer)
learning_rate: 1e-4
lr_stage2: 1e-5
weight_decay: 0.01
epochs_stage1: 10
lambda_flow: 1.0
lambda_ce: 1.0
compile: false
